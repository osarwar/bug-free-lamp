{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward Stepwise Selection Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we compare the results from 2 ways to perform forward stepwise selection. The variable that most decreases the residual sum of squared error (RSS) can be selected in the following ways: \n",
    "1. Solving least-squares problems for all potential additional regressors at each step as is commonly done (e.g. in ALAMO)\n",
    "2. Selecting the variable with greatest abosolute correlaction to the residual (as in the \"Least Angle Regression\" (Efron, Hastie, Johnston, & Tibshirani, 2004). Available: http://statweb.stanford.edu/~tibs/ftp/lars.pdf  \n",
    "2b. Using method 2, as implemented in Tibshirani's \"best-subset\" package. Available: https://github.com/ryantibs/best-subset/blob/master/bestsubset.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from RandomizedRoundingforBSS import * \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from copy import copy \n",
    "\n",
    "#Generate Data\n",
    "\n",
    "p = 23 #Number potential regressors\n",
    "n = 40 #Number of data points \n",
    "DM = BuildDataArrays_and_OptimizationModels(n, p, \n",
    "            0, 1, 1,\n",
    "            0.1, 2, 2)\n",
    "LAU = LinAlgandUpdates(x=DM.x_train, y=DM.y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Solving Least Squares "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence of Regressors Added: [0, 22, 16, 14, 4, 12, 17, 19, 18, 20, 3, 7, 2, 10, 1, 8, 5, 11, 6, 13, 15, 9, 21]\n",
      "Sequence of RSS: [29.666003918986146, 25.61738552082976, 23.064875272804283, 20.924538648074375, 19.01969433731825, 17.117704964904547, 14.883156915467518, 13.537549623398428, 12.465669897067354, 11.286964383868195, 10.40777034616362, 9.56696289119194, 9.120637871956077, 8.682208765261063, 8.444878837582822, 8.008391937153844, 7.6949112537568825, 7.489188912701578, 7.311282739785581, 7.113290880818886, 6.955656320650854, 6.752283037407808, 6.59582851215833]\n"
     ]
    }
   ],
   "source": [
    "regressors = np.zeros(p) #Null model \n",
    "step_sequence = []\n",
    "objective_sequence = []\n",
    "\n",
    "while False in (regressors==1): #while not all regressors selected \n",
    "    opt_step_obj = 1000000\n",
    "    for regressor in range(p): #solve least squares problem for each possible regressor \n",
    "        step_regressors = copy(regressors)\n",
    "        if step_regressors[regressor] == 0: \n",
    "            step_regressors[regressor] = 1 \n",
    "            test_step_obj, _, _ = LAU.evaluate_obj(step_regressors, 0, 'arbitrary', n) \n",
    "            if test_step_obj < opt_step_obj: \n",
    "                opt_step_obj = test_step_obj\n",
    "                opt_regressors = copy(step_regressors)\n",
    "                step = copy(regressor)\n",
    "    regressors = copy(opt_regressors)\n",
    "    step_sequence.append(step)\n",
    "    objective_sequence.append(opt_step_obj)\n",
    "    \n",
    "print('Sequence of Regressors Added:', step_sequence)\n",
    "print('Sequence of RSS:', objective_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Maximizing Absolute Correlation to Residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence of Regressors Added: [0, 22, 16, 14, 4, 12, 17, 19, 7, 18, 20, 3, 2, 10, 1, 8, 11, 6, 5, 15, 13, 9, 21]\n",
      "Sequence of RSS: [29.66600391898614, 25.617385520829778, 23.06487527280429, 20.924538648074364, 19.019694337318235, 17.117704964904544, 14.883156915467508, 13.53754962339842, 12.481457239611832, 11.427064729063517, 10.481458990054497, 9.56696289119193, 9.120637871956065, 8.682208765261054, 8.444878837582813, 8.008391937153835, 7.74360546597418, 7.562451200207468, 7.311282739785576, 7.143548345064097, 6.955656320650851, 6.752283037407811, 6.5958285121583335]\n"
     ]
    }
   ],
   "source": [
    "regressors = np.zeros(p) #Null model \n",
    "step_sequence_2 = []\n",
    "objective_sequence_2 = []\n",
    "\n",
    "model = np.zeros((n,1)) #initial null model \n",
    "x = copy(DM.x_train)\n",
    "xT = copy(x.T) #Transpose of design matrix \n",
    "while False in (regressors==1):\n",
    "    if len(step_sequence_2) != 0: #if model non-empty \n",
    "        for row in range(xT.shape[0]): #orthogonalize other predictors w.r.t. currently chosen predictor  \n",
    "            if row != step_regressor:\n",
    "                m = (xT[row].dot(xT[step_regressor]))/(sum(i**2 for i in xT[step_regressor]))*(xT[step_regressor])\n",
    "                xT[row] = xT[row] - m.flatten() \n",
    "    correlation = xT.dot(DM.y_train.flatten() - model.flatten()) #calculate correlation vector \n",
    "    step_regressor = np.argmax(np.abs(correlation)) #find regressor with greatest abs correlation \n",
    "    step_sequence_2.append(step_regressor)\n",
    "    regressors[step_regressor] = 1 #add regressor \n",
    "    test_step_obj, B_ols, _ = LAU.evaluate_obj(regressors, 0, 'arbitrary', n) #calculate new RSS\n",
    "    objective_sequence_2.append(test_step_obj)\n",
    "    B = np.zeros(p)\n",
    "    j = 0 \n",
    "    for i in range(len(regressors)): \n",
    "        if regressors[i] == 1: \n",
    "            B[i] = B_ols[j]\n",
    "            j+=1 \n",
    "    model = model.flatten() + B[step_regressor]*xT[step_regressor] #update model \n",
    "    model = model.reshape((n,1))\n",
    "\n",
    "\n",
    "print('Sequence of Regressors Added:', step_sequence_2)\n",
    "print('Sequence of RSS:', objective_sequence_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2b. Tibshirani 'best-subset' Package Implementation (Using Method 2 Above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence of Regressors Added: [ 0 22 16 14  4 12 17 19 18 20  3  7  2 10  1  8  5 11  6 13 15  9 21]\n"
     ]
    }
   ],
   "source": [
    "FSsoln = bestsubset_tibshirani.fs(DM.x_train_R, DM.y_train_R,intercept=False)\n",
    "print('Sequence of Regressors Added:', np.array(FSsoln[0],dtype=int)-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "Here, we summarize the order of regressor addition given by the methods shown above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Method 1 (LSTSQ)  Method 2 (Abs. Correlation)  Method 2b (R Package)\n",
      "Step 1                  0                            0                      0\n",
      "Step 2                 22                           22                     22\n",
      "Step 3                 16                           16                     16\n",
      "Step 4                 14                           14                     14\n",
      "Step 5                  4                            4                      4\n",
      "Step 6                 12                           12                     12\n",
      "Step 7                 17                           17                     17\n",
      "Step 8                 19                           19                     19\n",
      "Step 9                 18                            7                     18\n",
      "Step 10                20                           18                     20\n",
      "Step 11                 3                           20                      3\n",
      "Step 12                 7                            3                      7\n",
      "Step 13                 2                            2                      2\n",
      "Step 14                10                           10                     10\n",
      "Step 15                 1                            1                      1\n",
      "Step 16                 8                            8                      8\n",
      "Step 17                 5                           11                      5\n",
      "Step 18                11                            6                     11\n",
      "Step 19                 6                            5                      6\n",
      "Step 20                13                           15                     13\n",
      "Step 21                15                           13                     15\n",
      "Step 22                 9                            9                      9\n",
      "Step 23                21                           21                     21\n"
     ]
    }
   ],
   "source": [
    "Steps = pd.DataFrame({'Method 1 (LSTSQ)': step_sequence, 'Method 2 (Abs. Correlation)': step_sequence_2, \n",
    "                      'Method 2b (R Package)': np.array(FSsoln[0],dtype=int)-1}, index=['Step '+ str(i+1) for i in range(p)])\n",
    "print(Steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
